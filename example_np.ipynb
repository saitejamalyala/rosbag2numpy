{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python378jvsc74a57bd0bbc9dda3e9e79c7f3242cc2df2a5d623228b80dc5b57011016029c4090ab57c9",
   "display_name": "Python 3.7.8 64-bit ('env_rosbag')"
  },
  "metadata": {
   "interpreter": {
    "hash": "bbc9dda3e9e79c7f3242cc2df2a5d623228b80dc5b57011016029c4090ab57c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bagpy\n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt \n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[INFO]  Data folder C:\\Users\\Teja\\Documents\\_INFOTECH\\Thesis\\sample_Ros_bag\\2021-03-12_11-41-55_0\\2021-03-12_11-41-55_0 already exists. Not creating.\n"
     ]
    }
   ],
   "source": [
    "from bagpy import bagreader\n",
    "\n",
    "b = bagreader(r'C:\\Users\\Teja\\Documents\\_INFOTECH\\Thesis\\sample_Ros_bag\\2021-03-12_11-41-55_0\\2021-03-12_11-41-55_0.bag')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "len\npathing_msgs 227\ngrid_msgs 746\nodom_msgs 5222\nimage_msgs 1315\n"
     ]
    }
   ],
   "source": [
    "bag = b.reader\n",
    "\n",
    "\n",
    "topic_list = ['/em/fused_grid', '/sensorik/axis_front/image/compressed', '/vehicle/odometry', '/function/pathing_mlteleop']\n",
    "\n",
    "\n",
    "pathing_msgs = []\n",
    "grid_msgs = []\n",
    "grid_seqs = []\n",
    "odom_msgs = []\n",
    "odom_seqs = []\n",
    "image_msgs = []\n",
    "image_seqs = []\n",
    "count = 0\n",
    "for topic, msg, t in bag.read_messages(topics=topic_list):\n",
    "    if topic == \"/function/pathing_mlteleop\":\n",
    "        pathing_msgs.append(msg)\n",
    "\n",
    "    if topic == \"/em/fused_grid\":\n",
    "        grid_msgs.append(msg)\n",
    "        grid_seqs.append(msg.header.seq)\n",
    "        \n",
    "    if topic == \"/vehicle/odometry\":\n",
    "        odom_msgs.append(msg)\n",
    "        odom_seqs.append(msg.header.seq)\n",
    "    if topic == \"/sensorik/axis_front/image/compressed\":\n",
    "        image_msgs.append(msg)\n",
    "        image_seqs.append(msg.header.seq)\n",
    "    if count==10000:\n",
    "        break\n",
    "    else: count +=1\n",
    "bag.close()\n",
    "\n",
    "print('len')\n",
    "print('pathing_msgs',len(pathing_msgs))\n",
    "print('grid_msgs',len(grid_msgs))\n",
    "print('odom_msgs',len(odom_msgs))\n",
    "print('image_msgs',len(image_msgs))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "_READ_ROSBAG =1\n",
    "_MAX_LENGTH = 25\n",
    "_ZERO_PADDING = 1\n",
    "\n",
    "class np_maker():\n",
    "\n",
    "    def __init__(self,pathing_msgs,max_length):\n",
    "        self.pathing_msgs = pathing_msgs\n",
    "        self.max_length = max_length\n",
    "        self.extract_msg_cnt = 220\n",
    "\n",
    "    @staticmethod\n",
    "    def __np_reshape_frm_list(list_path,new_shape):\n",
    "        return np.reshape((np.asarray(list_path)),new_shape)\n",
    "    \n",
    "    @staticmethod\n",
    "    def __np_hstack_list(self,list1,list2,new_shape):\n",
    "        assert len(list1)==len(list2)\n",
    "        np_list1 = self.__np_reshape_frm_list(list1,new_shape)\n",
    "        np_list2 = self.__np_reshape_frm_list(list2,new_shape)\n",
    "        return np.hstack((np_list1,np_list2))\n",
    "    \n",
    "    @staticmethod\n",
    "    def __padd_values(n,val):\n",
    "        listofzeros = [val] * n\n",
    "        return listofzeros\n",
    "    \n",
    "    @staticmethod\n",
    "    def __padded_path(self,unpadded_path):\n",
    "        padded_path = unpadded_path.extend(self.__padd_values(self.max_length-len(unpadded_path),0))\n",
    "        return padded_path\n",
    "\n",
    "    @staticmethod\n",
    "    def __construct_path(list_of_points):\n",
    "        path_x = [] \n",
    "        path_y = []\n",
    "        for path in list_of_points:\n",
    "            path_x.append(path.point.x)\n",
    "            path_y.append(path.point.y)\n",
    "\n",
    "        return path_x,path_y  \n",
    "\n",
    "    @staticmethod\n",
    "    def __assert_all_lengths(self,path1_x,path1_y,path2_x,path2_y):\n",
    "        # check if every path is as long as the maximum length\n",
    "        assert len(path1_x)==self.max_length \n",
    "        assert len(path1_y)==self.max_length \n",
    "        assert len(path2_x)==self.max_length \n",
    "        assert len(path2_y)==self.max_length\n",
    "\n",
    "    def create_np_path(self):\n",
    "\n",
    "        list_all_init_path = []\n",
    "        list_all_opt_path = []\n",
    "        print(\"Converting path data to numpy........ \")\n",
    "        for i,examplary_pathing_msg in enumerate(tqdm(self.pathing_msgs)):\n",
    "\n",
    "            init_path_x,init_path_y = self.__construct_path(examplary_pathing_msg.path_options[0].reference_path)\n",
    "\n",
    "            opt_path_x,opt_path_y = self.__construct_path(examplary_pathing_msg.path_options[2].reference_path)\n",
    "\n",
    "            if _ZERO_PADDING:\n",
    "                if len(init_path_x)<self.max_length:\n",
    "                    init_path_x.extend(self.__padd_values(self.max_length-len(init_path_x),0))\n",
    "                    #init_path_x = self.__padded_path(self,init_path_x)\n",
    "                    init_path_y.extend(self.__padd_values(self.max_length-len(init_path_y),0))\n",
    "            \n",
    "                if len(opt_path_x)<self.max_length:\n",
    "                    opt_path_x.extend(self.__padd_values(self.max_length-len(opt_path_x),0))\n",
    "                    opt_path_y.extend(self.__padd_values(self.max_length-len(opt_path_y),0))\n",
    "            \n",
    "            #check for length\n",
    "            self.__assert_all_lengths(self,init_path_x,init_path_y,opt_path_x,opt_path_y)\n",
    "\n",
    "            #pair x and y and \n",
    "            np_init_path = self.__np_hstack_list(self,init_path_x,init_path_y,new_shape=(self.max_length,1))\n",
    "            np_opt_path = self.__np_hstack_list(self,opt_path_x,opt_path_y,new_shape=(self.max_length,1))\n",
    "            \n",
    "            # append paths from all pathing messages\n",
    "            list_all_init_path.append(np_init_path)\n",
    "            list_all_opt_path.append(np_opt_path)\n",
    "\n",
    "        # Convert the all paths appended list to numpy array\n",
    "        np_all_initp = np.asarray(list_all_init_path)\n",
    "        np_all_optp = np.asarray(list_all_opt_path)        \n",
    "\n",
    "        return np_all_initp,np_all_optp\n",
    "\n",
    "    def create_np_grid(self):\n",
    "\n",
    "        list_all_grid_data =[]\n",
    "        print(\"Converting grid data to numpy........ \")\n",
    "        for i,examplary_pathing_msg in enumerate(tqdm(self.pathing_msgs)):\n",
    "\n",
    "            #get sequences aligning with pathing messages\n",
    "            grid_seq = examplary_pathing_msg.path_options[1].reference_path[0].left_boundaries.lane\n",
    "\n",
    "            \"\"\"\n",
    "            grid is saved as vector in grid_msg.data\n",
    "            grid_msg.info gives information about properties, i.e. width, height, resolution, position in odometry frame\n",
    "            \"\"\"\n",
    "            grid_idx = grid_seqs.index(grid_seq)\n",
    "            grid_msg = grid_msgs[grid_idx]\n",
    "\n",
    "            grid_data = np.asarray(grid_msg.data)\n",
    "            grid_data = grid_data.reshape(grid_msg.info.width, grid_msg.info.height)\n",
    "            \n",
    "            # append grid data\n",
    "            list_all_grid_data.append(grid_data) \n",
    "\n",
    "        #converted appended grids to np array\n",
    "        np_all_grid_data = np.asarray(list_all_grid_data)\n",
    "\n",
    "        return np_all_grid_data\n",
    "\n",
    "    def create_np_img(self):\n",
    "        list_all_img_data =[]\n",
    "        print(\"Converting grid data to numpy........ \")\n",
    "        for i,examplary_pathing_msg in enumerate(tqdm(self.pathing_msgs[0:2])):\n",
    "\n",
    "            image_seq = examplary_pathing_msg.path_options[1].reference_path[0].left_boundaries.road\n",
    "            image_idx = image_seqs.index(image_seq)\n",
    "            image_msg = image_msgs[image_idx]\n",
    "            # Convert compressed image to RAW\n",
    "            bridge = CvBridge()\n",
    "            img = bridge.compressed_imgmsg_to_cv2(image_msg)\n",
    "            list_all_img_data.append(img)\n",
    "\n",
    "        np_all_img_data = np.asarray(list_all_img_data)\n",
    "\n",
    "        return np_all_img_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 227/227 [00:00<00:00, 13330.72it/s]\n",
      "  0%|          | 1/227 [00:00<00:29,  7.69it/s]Converting path data to numpy........ \n",
      "Converting grid data to numpy........ \n",
      "100%|██████████| 227/227 [00:28<00:00,  7.83it/s]\n",
      "(227, 25, 2)\n",
      "(227, 1536, 1536)\n"
     ]
    }
   ],
   "source": [
    "convert_2_np = np_maker(pathing_msgs,25)\n",
    "np_init_path,np_opt_path = convert_2_np.create_np_path()\n",
    "np_grid_data = convert_2_np.create_np_grid()\n",
    "print(np.shape(np_init_path))\n",
    "print(np.shape(np_grid_data))"
   ]
  },
  {
   "source": [
    "np.save('_np_initpath',np_init_path)\n",
    "np.save('_np_optpath',np_opt_path)\n",
    "np.save('_np_griddata',np_grid_data)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_grid_data = np.load('_np_griddata.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "np_grid_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "examplary_pathing_msg\n"
     ]
    }
   ],
   "source": [
    "# Example for a single pathing_msg:\n",
    "init_path_x = []\n",
    "init_path_y = []\n",
    "opt_path_x = []\n",
    "opt_path_y = []\n",
    "\n",
    "grid_msg = None\n",
    "image_msg = None\n",
    "odom_msg = None\n",
    "\n",
    "max_length = 25\n",
    "np_init_paths = np.empty((1,max_length,2))\n",
    "\n",
    "for examplary_pathing_msg in pathing_msgs[0:1]:\n",
    "    #examplary_pathing_msg = pathing_msgs[0]\n",
    "    \n",
    "    print(\"examplary_pathing_msg\")\n",
    "    #print(examplary_pathing_msg)\n",
    "\n",
    "    '''\n",
    "    for init_path in examplary_pathing_msg.path_options[0].reference_path:\n",
    "        init_path_x.append(init_path.point.x)\n",
    "        init_path_y.append(init_path.point.y)\n",
    "    '''\n",
    "    init_path_x, init_path_y = construct_path(examplary_pathing_msg.path_options[0].reference_path)\n",
    "    init_path_x = padd_w_value(init_path_x,0,25)\n",
    "    opt_path_x, opt_path_y = construct_path(examplary_pathing_msg.path_options[2].reference_path)\n",
    "\n",
    "    '''\n",
    "    for opt_path in examplary_pathing_msg.path_options[2].reference_path:\n",
    "        opt_path_x.append(opt_path.point.x)\n",
    "        opt_path_y.append(opt_path.point.y)\n",
    "    '''\n",
    "    # corresponding occupancy grid, camera and odometry sequences (ID's):\n",
    "    # this saving method is a workaround for the corresponding ID's\n",
    "    grid_seq = examplary_pathing_msg.path_options[1].reference_path[0].left_boundaries.lane\n",
    "    image_seq = examplary_pathing_msg.path_options[1].reference_path[0].left_boundaries.road\n",
    "    odom_seq = examplary_pathing_msg.path_options[1].reference_path[0].left_boundaries.obstacle\n",
    "\n",
    "    # corresponding occupancy grid, camera and odometry messages:\n",
    "    \"\"\"\n",
    "    grid is saved as vector in grid_msg.data\n",
    "    grid_msg.info gives information about properties, i.e. width, height, resolution, position in odometry frame\n",
    "    \"\"\"\n",
    "    grid_idx = grid_seqs.index(grid_seq)\n",
    "    grid_msg = grid_msgs[grid_idx]\n",
    "    # print('grid_msg.info')\n",
    "    # print(grid_msg.info)\n",
    "\n",
    "    \"\"\"\n",
    "    1280x720, RGB Image\n",
    "    \"\"\"\n",
    "    image_idx = image_seqs.index(image_seq)\n",
    "    image_msg = image_msgs[image_idx]\n",
    "    # Convert compressed image to RAW\n",
    "    #bridge = CvBridge()\n",
    "    #img = bridge.compressed_imgmsg_to_cv2(image_msg)\n",
    "    # print(img.shape)\n",
    "\n",
    "    \"\"\"\n",
    "    odom_msg provides information about the current position in the odometry frame (pos_x, pos_y, heading)\n",
    "    the idea is to provide the NN information for the correlation between camera image, the corresponding car position and the path to be optimized/predicted\n",
    "    \"\"\"\n",
    "    odom_idx = odom_seqs.index(odom_seq)\n",
    "    odom_msg = odom_msgs[odom_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}