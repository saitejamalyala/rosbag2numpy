{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.8 64-bit ('env_rosbag': venv)"
  },
  "interpreter": {
   "hash": "bbc9dda3e9e79c7f3242cc2df2a5d623228b80dc5b57011016029c4090ab57c9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "from typing import List,Tuple\n",
    "from data_loader import dataset_loader\n",
    "print(tf.__version__)\n",
    "#print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Building Dataset.......\n\n((TensorSpec(shape=(None, 1536, 1536), dtype=tf.int8, name=None),\n  TensorSpec(shape=(None, None), dtype=tf.float32, name=None),\n  TensorSpec(shape=(None, 25, 2), dtype=tf.float32, name=None),\n  TensorSpec(shape=(None, 25, 2), dtype=tf.float32, name=None),\n  TensorSpec(shape=(None, None), dtype=tf.float32, name=None),\n  TensorSpec(shape=(None, 25, 2), dtype=tf.float32, name=None)),\n TensorSpec(shape=(None, 25, 2), dtype=tf.float32, name=None))\n"
     ]
    }
   ],
   "source": [
    "ds_loader = dataset_loader(tfrec_dir=r'D:\\tf_records',batch_size=8)\n",
    "ds_train,ds_valid,ds_test= ds_loader.build_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "\n",
    "def euclidean_distance_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Euclidean distance loss\n",
    "    https://en.wikipedia.org/wiki/Euclidean_distance\n",
    "    :param y_true: TensorFlow tensor\n",
    "    :param y_p red: TensorFlow tensor of the same shape as y_true\n",
    "    :return: float\n",
    "    \"\"\"\n",
    "    #original euclidean distance loss =  K.sqrt(K.sum(K.square(y_pred - y_true), axis=-1))\n",
    "    loss = K.mean(K.sqrt(K.sum(K.square(y_pred - y_true), axis=-1)))\n",
    "    return loss\n",
    "\n",
    "\n",
    "#(example[\"grid_map\"],example[\"grid_org_res\"],example[\"left_bnd\"],example[\"right_bnd\"],example#[\"car_odo\"],example[\"init_path\"])\n",
    "\n",
    "def nn():\n",
    "\n",
    "    # Grid Map input\n",
    "    ip_gridmap = layers.Input(shape=(1536,1536,1))\n",
    "\n",
    "    #CNN - branch1\n",
    "    x_A = layers.Conv2D(16,kernel_size=7,strides=2)(ip_gridmap)\n",
    "    x_A = layers.BatchNormalization()(x_A)\n",
    "    x_A = layers.ReLU()(x_A)\n",
    "    x_A = layers.AvgPool2D(pool_size=(4,4))(x_A)\n",
    "\n",
    "    x_A = layers.Conv2D(32,kernel_size=5,strides=2)(x_A)\n",
    "    x_A = layers.BatchNormalization()(x_A)\n",
    "    x_A = layers.ReLU()(x_A)\n",
    "    x_A = layers.AvgPool2D(pool_size=(4,4))(x_A)\n",
    "\n",
    "    \n",
    "    x_A = layers.Conv2D(64,kernel_size=3,strides=2)(x_A)\n",
    "    x_A = layers.BatchNormalization()(x_A)\n",
    "    x_A = layers.ReLU()(x_A)\n",
    "    x_A = layers.AvgPool2D(pool_size=(2,2))(x_A)\n",
    "\n",
    "\n",
    "    x_A = layers.Flatten()(x_A)\n",
    "\n",
    "\n",
    "    # Other inputs\n",
    "    ip_grid_org_res = layers.Input(shape=(3,))\n",
    "    ip_left_bnd = layers.Input(shape=(25,2))\n",
    "    ip_right_bnd = layers.Input(shape=(25,2))\n",
    "    ip_car_odo = layers.Input(shape=(3,))\n",
    "    ip_init_path = layers.Input(shape=(25,2))\n",
    "    #branch 2\n",
    "    x_B = layers.Conv1D(2,kernel_size=3,padding='same')(ip_init_path)\n",
    "    #branch 3\n",
    "    x_C = layers.Conv1D(2,kernel_size=3,padding='same')(ip_left_bnd)\n",
    "    #branch 4\n",
    "    x_D = layers.Conv1D(2,kernel_size=3,padding='same')(ip_right_bnd)\n",
    "    # branch 5\n",
    "    conc_grid_orgres_car_odo = layers.concatenate([ip_grid_org_res,ip_car_odo])\n",
    "\n",
    "\n",
    "    reshape_init_path = layers.Reshape((50,))(x_B)\n",
    "    reshape_left_bnd = layers.Reshape((50,))(x_C)\n",
    "    reshape_right_bnd = layers.Reshape((50,))(x_D)\n",
    "\n",
    "    \n",
    "    #concatenate feature\n",
    "    concat_feat = layers.concatenate([x_A, reshape_init_path, reshape_left_bnd, reshape_right_bnd, conc_grid_orgres_car_odo])\n",
    "\n",
    "    #concat_feat = layers.Lambda(lambda x: tf.expand_dims(x, -1))(concat_feat)\n",
    "\n",
    "    #FC\n",
    "    #output = layers.Convolution1D(50,kernel_size=3,padding='valid',activation='relu')(concat_feat)\n",
    "    \n",
    "    output = layers.Dense(50, activation='linear')(concat_feat)\n",
    "\n",
    "    output = layers.Dropout(0.6)(output)\n",
    "    \n",
    "    output = layers.Dense(50, activation='linear')(output)\n",
    "    \n",
    "    output = layers.Reshape((25,2))(output)\n",
    "    \n",
    "    nn_fun = keras.models.Model(inputs = [ip_gridmap,ip_grid_org_res,ip_left_bnd, ip_right_bnd, ip_car_odo, ip_init_path], outputs= output)\n",
    "    \n",
    "    return nn_fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_3\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_19 (InputLayer)           [(None, 1536, 1536,  0                                            \n__________________________________________________________________________________________________\nconv2d_9 (Conv2D)               (None, 765, 765, 16) 800         input_19[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_9 (BatchNor (None, 765, 765, 16) 64          conv2d_9[0][0]                   \n__________________________________________________________________________________________________\nre_lu_9 (ReLU)                  (None, 765, 765, 16) 0           batch_normalization_9[0][0]      \n__________________________________________________________________________________________________\naverage_pooling2d_9 (AveragePoo (None, 191, 191, 16) 0           re_lu_9[0][0]                    \n__________________________________________________________________________________________________\nconv2d_10 (Conv2D)              (None, 94, 94, 32)   12832       average_pooling2d_9[0][0]        \n__________________________________________________________________________________________________\nbatch_normalization_10 (BatchNo (None, 94, 94, 32)   128         conv2d_10[0][0]                  \n__________________________________________________________________________________________________\nre_lu_10 (ReLU)                 (None, 94, 94, 32)   0           batch_normalization_10[0][0]     \n__________________________________________________________________________________________________\naverage_pooling2d_10 (AveragePo (None, 23, 23, 32)   0           re_lu_10[0][0]                   \n__________________________________________________________________________________________________\nconv2d_11 (Conv2D)              (None, 11, 11, 64)   18496       average_pooling2d_10[0][0]       \n__________________________________________________________________________________________________\nbatch_normalization_11 (BatchNo (None, 11, 11, 64)   256         conv2d_11[0][0]                  \n__________________________________________________________________________________________________\nre_lu_11 (ReLU)                 (None, 11, 11, 64)   0           batch_normalization_11[0][0]     \n__________________________________________________________________________________________________\ninput_24 (InputLayer)           [(None, 25, 2)]      0                                            \n__________________________________________________________________________________________________\ninput_21 (InputLayer)           [(None, 25, 2)]      0                                            \n__________________________________________________________________________________________________\ninput_22 (InputLayer)           [(None, 25, 2)]      0                                            \n__________________________________________________________________________________________________\naverage_pooling2d_11 (AveragePo (None, 5, 5, 64)     0           re_lu_11[0][0]                   \n__________________________________________________________________________________________________\nconv1d_9 (Conv1D)               (None, 25, 2)        14          input_24[0][0]                   \n__________________________________________________________________________________________________\nconv1d_10 (Conv1D)              (None, 25, 2)        14          input_21[0][0]                   \n__________________________________________________________________________________________________\nconv1d_11 (Conv1D)              (None, 25, 2)        14          input_22[0][0]                   \n__________________________________________________________________________________________________\ninput_20 (InputLayer)           [(None, 3)]          0                                            \n__________________________________________________________________________________________________\ninput_23 (InputLayer)           [(None, 3)]          0                                            \n__________________________________________________________________________________________________\nflatten_3 (Flatten)             (None, 1600)         0           average_pooling2d_11[0][0]       \n__________________________________________________________________________________________________\nreshape_12 (Reshape)            (None, 50)           0           conv1d_9[0][0]                   \n__________________________________________________________________________________________________\nreshape_13 (Reshape)            (None, 50)           0           conv1d_10[0][0]                  \n__________________________________________________________________________________________________\nreshape_14 (Reshape)            (None, 50)           0           conv1d_11[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_6 (Concatenate)     (None, 6)            0           input_20[0][0]                   \n                                                                 input_23[0][0]                   \n__________________________________________________________________________________________________\nconcatenate_7 (Concatenate)     (None, 1756)         0           flatten_3[0][0]                  \n                                                                 reshape_12[0][0]                 \n                                                                 reshape_13[0][0]                 \n                                                                 reshape_14[0][0]                 \n                                                                 concatenate_6[0][0]              \n__________________________________________________________________________________________________\ndense_6 (Dense)                 (None, 50)           87850       concatenate_7[0][0]              \n__________________________________________________________________________________________________\ndropout_3 (Dropout)             (None, 50)           0           dense_6[0][0]                    \n__________________________________________________________________________________________________\ndense_7 (Dense)                 (None, 50)           2550        dropout_3[0][0]                  \n__________________________________________________________________________________________________\nreshape_15 (Reshape)            (None, 25, 2)        0           dense_7[0][0]                    \n==================================================================================================\nTotal params: 123,018\nTrainable params: 122,794\nNon-trainable params: 224\n__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pp_model = nn()\n",
    "opt = tf.keras.optimizers.Adam()\n",
    "pp_model.compile(optimizer=opt,loss=euclidean_distance_loss, metrics='accuracy')\n",
    "pp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[8,16,765,765] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradient_tape/model_3/average_pooling2d_9/AvgPool/AvgPoolGrad (defined at <ipython-input-20-882490cdecf5>:1) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_6688]\n\nFunction call stack:\ntrain_function\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-882490cdecf5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpp_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mds_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Teja\\Documents\\_INFOTECH\\Thesis\\sample_Ros_bag\\env_rosbag\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Teja\\Documents\\_INFOTECH\\Thesis\\sample_Ros_bag\\env_rosbag\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Teja\\Documents\\_INFOTECH\\Thesis\\sample_Ros_bag\\env_rosbag\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    886\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 888\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    889\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Teja\\Documents\\_INFOTECH\\Thesis\\sample_Ros_bag\\env_rosbag\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Teja\\Documents\\_INFOTECH\\Thesis\\sample_Ros_bag\\env_rosbag\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Teja\\Documents\\_INFOTECH\\Thesis\\sample_Ros_bag\\env_rosbag\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\Users\\Teja\\Documents\\_INFOTECH\\Thesis\\sample_Ros_bag\\env_rosbag\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[8,16,765,765] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradient_tape/model_3/average_pooling2d_9/AvgPool/AvgPoolGrad (defined at <ipython-input-20-882490cdecf5>:1) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_6688]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "history = pp_model.fit(ds_train,epochs=1,validation_data=ds_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}